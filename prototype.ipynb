{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b98bb96-89b6-4055-80f8-089c8643bd6c",
   "metadata": {},
   "source": [
    "- Models\n",
    "    - distilbert\n",
    "        - https://huggingface.co/distilbert-base-uncased-distilled-squad\n",
    "        - word count restricted to 512\n",
    "        - appropriate for page summaries\n",
    "    - look into\n",
    "        - longform\n",
    "            - https://medium.com/dair-ai/longformer-what-bert-should-have-been-78f4cd595be9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fb1c037d-237f-4db7-8323-2bc8b0afb2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "73ebb442-dabc-4882-ae0e-6edb9fe41b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distilbert_ask(question, text):\n",
    "    inputs = tokenizer(question, text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    answer_start_index = outputs.start_logits.argmax()\n",
    "    answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    return tokenizer.decode(predict_answer_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98241bf5-94c3-4a8d-824f-95a2425878b3",
   "metadata": {},
   "source": [
    "# Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "985ee67b-ca50-4d2c-b1d9-829652e44987",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_pages = '''\n",
    "Cluster analysis\n",
    "Supervised learning\n",
    "Decision tree learning\n",
    "Ensemble learning\n",
    "Bootstrap aggregating\n",
    "Boosting (machine learning)\n",
    "\n",
    "\n",
    "\n",
    "Statistical classification\n",
    "k-means clustering\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13dcfc5a-0a05-41e8-aedd-5bbb4547d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3c463dc-efd1-491d-9f46-6a02f02ada86",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e9c3d804-342b-47ee-bc5d-4f78c01dfdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "wikipedia page title: k means\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "summary:\n",
      "\n",
      "k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells. k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances. For instance, better Euclidean solutions can be found using k-medians and k-medoids.\n",
      "The problem is computationally difficult (NP-hard); however, efficient heuristic algorithms converge quickly to a local optimum. These are usually similar to the expectation-maximization algorithm for mixtures of Gaussian distributions via an iterative refinement approach employed by both k-means and Gaussian mixture modeling. They both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the Gaussian mixture model allows clusters to have different shapes.\n",
      "The unsupervised k-means algorithm has a loose relationship to the k-nearest neighbor classifier, a popular supervised machine learning technique for classification that is often confused with k-means due to the name. Applying the 1-nearest neighbor classifier to the cluster centers obtained by k-means classifies new data into the existing clusters. This is known as nearest centroid classifier or Rocchio algorithm.\n"
     ]
    }
   ],
   "source": [
    "page_title = input('wikipedia page title:')\n",
    "page_py = wiki_wiki.page(page_title)\n",
    "if not page_py.exists():\n",
    "    print('page does not exist')\n",
    "else:\n",
    "    print('\\nsummary:\\n')\n",
    "    print(page_py.summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8c2212a5-3217-4c8f-8a01-b835d78f8083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Category:Articles with short description': Category:Articles with short description (id: ??, ns: 14),\n",
       " 'Category:CS1 French-language sources (fr)': Category:CS1 French-language sources (fr) (id: ??, ns: 14),\n",
       " 'Category:CS1 errors: missing periodical': Category:CS1 errors: missing periodical (id: ??, ns: 14),\n",
       " 'Category:Cluster analysis algorithms': Category:Cluster analysis algorithms (id: ??, ns: 14),\n",
       " 'Category:Short description is different from Wikidata': Category:Short description is different from Wikidata (id: ??, ns: 14)}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_py.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "11542e3a-5e11-4bba-94e9-b0c8aa26878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "question:\n",
      " which metric?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'squared euclidean distances'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = input('question:\\n')\n",
    "distilbert_ask(question, page_py.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "369a554d-87a9-425f-8be8-2755aaada47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Affinity propagation': Affinity propagation (id: ??, ns: 0),\n",
       " 'Automatic clustering algorithms': Automatic clustering algorithms (id: ??, ns: 0),\n",
       " 'BFR algorithm': BFR algorithm (id: ??, ns: 0),\n",
       " 'BIRCH': BIRCH (id: ??, ns: 0),\n",
       " 'Canopy clustering algorithm': Canopy clustering algorithm (id: ??, ns: 0),\n",
       " 'Chinese whispers (clustering method)': Chinese whispers (clustering method) (id: ??, ns: 0),\n",
       " 'Cluster-weighted modeling': Cluster-weighted modeling (id: ??, ns: 0),\n",
       " 'Cobweb (clustering)': Cobweb (clustering) (id: ??, ns: 0),\n",
       " 'Complete-linkage clustering': Complete-linkage clustering (id: ??, ns: 0),\n",
       " 'Constrained clustering': Constrained clustering (id: ??, ns: 0),\n",
       " 'CURE algorithm': CURE algorithm (id: ??, ns: 0),\n",
       " 'Data stream clustering': Data stream clustering (id: ??, ns: 0),\n",
       " 'DBSCAN': DBSCAN (id: ??, ns: 0),\n",
       " 'Expectation–maximization algorithm': Expectation–maximization algorithm (id: ??, ns: 0),\n",
       " 'FLAME clustering': FLAME clustering (id: ??, ns: 0),\n",
       " 'Fuzzy clustering': Fuzzy clustering (id: ??, ns: 0),\n",
       " 'Hierarchical clustering': Hierarchical clustering (id: ??, ns: 0),\n",
       " 'Hoshen–Kopelman algorithm': Hoshen–Kopelman algorithm (id: ??, ns: 0),\n",
       " 'Information bottleneck method': Information bottleneck method (id: ??, ns: 0),\n",
       " 'Jenks natural breaks optimization': Jenks natural breaks optimization (id: ??, ns: 0),\n",
       " 'K q-flats': K q-flats (id: ??, ns: 0),\n",
       " 'K-means clustering': K-means clustering (id: ??, ns: 0),\n",
       " 'K-means++': K-means++ (id: ??, ns: 0),\n",
       " 'K-medians clustering': K-medians clustering (id: ??, ns: 0),\n",
       " 'K-medoids': K-medoids (id: ??, ns: 0),\n",
       " 'K-SVD': K-SVD (id: ??, ns: 0),\n",
       " 'Linde–Buzo–Gray algorithm': Linde–Buzo–Gray algorithm (id: ??, ns: 0),\n",
       " 'Low-energy adaptive clustering hierarchy': Low-energy adaptive clustering hierarchy (id: ??, ns: 0),\n",
       " 'Mean shift': Mean shift (id: ??, ns: 0),\n",
       " 'Nearest-neighbor chain algorithm': Nearest-neighbor chain algorithm (id: ??, ns: 0),\n",
       " 'Neighbor joining': Neighbor joining (id: ??, ns: 0),\n",
       " 'OPTICS algorithm': OPTICS algorithm (id: ??, ns: 0),\n",
       " 'Pitman–Yor process': Pitman–Yor process (id: ??, ns: 0),\n",
       " 'Quantum clustering': Quantum clustering (id: ??, ns: 0),\n",
       " 'Self-organizing map': Self-organizing map (id: ??, ns: 0),\n",
       " 'SimRank': SimRank (id: ??, ns: 0),\n",
       " 'Single-linkage clustering': Single-linkage clustering (id: ??, ns: 0),\n",
       " 'Spectral clustering': Spectral clustering (id: ??, ns: 0),\n",
       " 'SUBCLU': SUBCLU (id: ??, ns: 0),\n",
       " 'UPGMA': UPGMA (id: ??, ns: 0),\n",
       " \"Ward's method\": Ward's method (id: ??, ns: 0),\n",
       " 'WPGMA': WPGMA (id: ??, ns: 0)}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search by category\n",
    "c = wiki_wiki.page('Category:Cluster analysis algorithms')\n",
    "c.categorymembers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
